{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cat-vs-dogs",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bne08/bne08/blob/master/cat_vs_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQQyfO1unnP",
        "colab_type": "code",
        "outputId": "4e9ef358-fbaf-4d65-9b0b-08f3c6e7bd61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "from google.colab import files\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas \n",
        "import os \n",
        "from random import shuffle\n",
        "import cv2\n",
        "\n",
        "\n",
        "TEST_KLASORU= '/content/drive/My Drive/Colab Notebooks/dogs-vs-catss/test1' \n",
        "EGITIM_KLASORU = '/content/drive/My Drive/Colab Notebooks/dogs-vs-catss/train'\n",
        "OGRENME_ORANI= 1e-3 #0.001\n",
        "MODEL_ADI= \"dogs-vs-cats-{}-{}.model\".format(OGRENME_ORANI,\"6conv-fire\")\n",
        "RESIM_BOYUTU = 50\n",
        "\n",
        "#! /usr/bin/env python\n",
        "\n",
        "def etiket_olustur(resim):           #goruntu adını bir diziye dönüştürmekte\n",
        "    resim_adi= resim.split(\".\")[-3] #dosya adında kullanılan \"cat\" yada \"dog\" kelimelerini al\n",
        "    if resim_adi == \"cat\": \n",
        "        return [1,0]     #fonksiyon dosya adı \"cat\" bu cıkısı verir.\n",
        "    elif resim_adi == \"dog\":\n",
        "        return [0,1]\n",
        "        #RESİMLERİN MATRİS HALİNE DONUSMESİ#\n",
        "\n",
        "def train_data_loader():\n",
        "    egitim_verisi_2 = []\n",
        "    for img in tqdm(os.listdir(EGITIM_KLASORU)):\n",
        "        img_lable = etiket_olustur(img)\n",
        "        path_to_img = os.path.join(EGITIM_KLASORU,img)\n",
        "        img = cv2.resize(cv2.imread(path_to_img,cv2.IMREAD_GRAYSCALE),(RESIM_BOYUTU,RESIM_BOYUTU))#resimler gri olarak okunup 50*50 piksel olacak sekilde yeniden boyutlandırılır\n",
        "        egitim_verisi_2.append([np.array(img),np.array(img_lable)])\n",
        "        \n",
        "    shuffle(egitim_verisi_2)#fonksiyon içindeki verilerin karsılastırılması saglanır\n",
        "    np.save(\"training_data_new.npy\",egitim_verisi_2)# olusturulan egitim verisi egitim_verisi.npy isimli dosyaya yazılır\n",
        "    return egitim_verisi_2\n",
        "\n",
        "\n",
        "def testing_data():  #test klasorundeki resimlerdem egitimde kullanılabilecek sekilde test verisi olusturur.\n",
        "    test_data = []\n",
        "    for img in tqdm(os.listdir(TEST_KLASORU)):\n",
        "        img_labels = img.split(\".\")[0]\n",
        "        path_to_img = os.path.join(TEST_KLASORU,img)\n",
        "        img = cv2.resize(cv2.imread(path_to_img,cv2.IMREAD_GRAYSCALE),(RESIM_BOYUTU,RESIM_BOYUTU))\n",
        "        test_data.append([np.array(img),np.array(img_labels)])\n",
        "        \n",
        "    shuffle(test_data)\n",
        "    np.save(\"test_dataone.npy\",test_data) #olusturulan test verisi olusturulan dosyaya yazılır\n",
        "    return test_data\n",
        "    \n",
        "train_data=train_data_loader()\n",
        "train_data_g = np.load('training_data_new.npy')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d,max_pool_2d\n",
        "from tflearn.layers.core import input_data,dropout,fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "\n",
        "import tensorflow as tf\n",
        " \n",
        "# MİMARİNİN OLUSURULMASI\n",
        "tf.reset_default_graph()\n",
        "#agın giriş boyutlarıının ne olacagı tanımlanır\n",
        "convnet = input_data(shape=[None, RESIM_BOYUTU, RESIM_BOYUTU, 1], name='input')\n",
        "#32 adet 5*5 boyutunda filtrelerden olusan ve relu aktivasyonu konvolusyon katmanı\n",
        "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "#5*5 boyutunda filtrelereden olusan katman\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "# Layer 2\n",
        "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "# Layer 3\n",
        "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "# Layer 4\n",
        "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "# Layer 5\n",
        "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "#1024 birimden olusan tam baglantılı ve relu aktivasyonlu katman\n",
        "convnet = fully_connected(convnet, 1024, activation='relu')\n",
        "#ezberlemeyi engellemek için dropout katmanı\n",
        "convnet = dropout(convnet, 0.8)\n",
        "#iki birimli ve softmax aktivasyonlu tam baglantılı katman\n",
        "convnet = fully_connected(convnet, 2, activation='softmax')\n",
        "#olusturulan mimariyi,ogrenme oranını,optimizasyon,optimizayon turunu,kayıp fonksiyonunu ve dosya isimlerinden aldıgımz hedef  aldıgımız hedef degeri\n",
        "#kullanarak agı olustur\n",
        "convnet = regression(convnet, optimizer='adam', learning_rate=OGRENME_ORANI, loss='categorical_crossentropy', name='targets')\n",
        "\n",
        "model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
        "\n",
        "#model.fit (X, Y, n_epoch = 6, validation_set = (test_x, test_y),görüntü_step = 500, show_metric = Doğru , run_id = MODEL_NAME)\n",
        "\n",
        "if os.path.exists(\"{}.meta\".format(MODEL_ADI)):\n",
        "    model.load(MODEL_ADI)\n",
        "    print(\"Model Loaded\")\n",
        "\n",
        "     #agı eğitirken 12500 adet resmi egitimi test etmek için kullanacagız\n",
        "\n",
        "egitim = train_data_g[:-12500]\n",
        "test = train_data_g[-12500:]\n",
        "\n",
        "X_egitim = np.array([i[0] for i in egitim]).reshape(-1, RESIM_BOYUTU, RESIM_BOYUTU, 1)\n",
        "y_egitim = [i[1] for i in egitim]\n",
        "X_test = np.array([i[0] for i in test]).reshape(-1, RESIM_BOYUTU, RESIM_BOYUTU, 1) \n",
        "y_test = [i[1] for i in test]\n",
        "\n",
        "model.fit(X_egitim, y_egitim, n_epoch=6, validation_set=(X_test,  y_test),\n",
        "    snapshot_step=500, show_metric=True, run_id=MODEL_ADI)\n",
        "\n",
        "model.save(MODEL_ADI)\n",
        "test_data = np.load(\"test_dataone.npy\")\n",
        "\n",
        "\n",
        "figs = plt.figure()\n",
        "testing_data()\n",
        "for num,data in enumerate(test_data[:10]):\n",
        "    test_img = data[0]\n",
        "    test_lable = data[1]\n",
        "    test_img_feed = test_img.reshape(RESIM_BOYUTU,RESIM_BOYUTU,1)\n",
        "    t = figs.add_subplot(3,4,num+1)\n",
        "    ores = test_img\n",
        "    model_pred = model.predict([test_img_feed])[0]\n",
        "    if np.argmax(model_pred) == 1:\n",
        "        pred_val = \"Dog\"\n",
        "    else:\n",
        "        pred_val = \"Cat\"\n",
        "        \n",
        "    t.imshow(ores,cmap=\"gray\")\n",
        "    plt.title(pred_val)\n",
        "\n",
        "    t.axes.get_xaxis().set_visible(False)\n",
        "    t.axes.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f2b52fefe79b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mtrain_data_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_data_new.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-f2b52fefe79b>\u001b[0m in \u001b[0;36mtrain_data_loader\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mimg_lable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metiket_olustur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mpath_to_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEGITIM_KLASORU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESIM_BOYUTU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRESIM_BOYUTU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#resimler gri olarak okunup 50*50 piksel olacak sekilde yeniden boyutlandırılır\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0megitim_verisi_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_lable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}